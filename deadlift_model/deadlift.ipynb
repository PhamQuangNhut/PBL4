{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import math\n",
    "# Drawing helpers\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine important landmarks for squat\n",
    "IMPORTANT_LMS = [\n",
    "    \"LEFT_SHOULDER\",\n",
    "    \"RIGHT_SHOULDER\",\n",
    "    \"LEFT_HIP\",\n",
    "    \"RIGHT_HIP\",\n",
    "    \"LEFT_WRIST\",\n",
    "    \"RIGHT_WRIST\",\n",
    "    \"LEFT_KNEE\",\n",
    "    \"RIGHT_KNEE\",\n",
    "    \"LEFT_ANKLE\",\n",
    "    \"RIGHT_ANKLE\"\n",
    "]\n",
    "\n",
    "# Generate all columns of the data frame\n",
    "\n",
    "headers = [\"label\"] # Label column\n",
    "\n",
    "for lm in IMPORTANT_LMS:\n",
    "    headers += [f\"{lm.lower()}_x\", f\"{lm.lower()}_y\", f\"{lm.lower()}_z\", f\"{lm.lower()}_v\"]\n",
    "    \n",
    "def extract_important_keypoints(results) -> list:\n",
    "    '''\n",
    "    Extract important keypoints from mediapipe pose detection\n",
    "    '''\n",
    "    landmarks = results.pose_landmarks.landmark\n",
    "\n",
    "    data = []\n",
    "    for lm in IMPORTANT_LMS:\n",
    "        keypoint = landmarks[mp_pose.PoseLandmark[lm].value]\n",
    "        data.append([keypoint.x, keypoint.y, keypoint.z, keypoint.visibility])\n",
    "    \n",
    "    return np.array(data).flatten().tolist()\n",
    "\n",
    "\n",
    "def rescale_frame(frame, percent=50):\n",
    "    '''\n",
    "    Rescale a frame to a certain percentage compare to its original frame\n",
    "    '''\n",
    "    width = int(frame.shape[1] * percent/ 100)\n",
    "    height = int(frame.shape[0] * percent/ 100)\n",
    "    dim = (width, height)\n",
    "    return cv2.resize(frame, dim, interpolation =cv2.INTER_AREA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = np.array([[1, 0, 0]])\n",
    "yaxis = np.array([[0, 1, 0]])\n",
    "zaxis = np.array([[0, 0, 1]])\n",
    "uaxis = np.array([[1, 1, 1]])\n",
    "analyzed_results = {\n",
    "     \"torso\": -1,\n",
    "     \"stance\":-1,\n",
    "     \"grip\":-1,\n",
    "     \"depth\":-1,\n",
    "     \"left_hand_straight\":-1,\n",
    "     \"right_hand_straight\":-1,\n",
    "     \"state\": -1  \n",
    "     }    \n",
    "def point_to_array(point) :\n",
    "     return np.array([point.x, point.y, point.z, point.visibility])\n",
    "def calculate_degree(pointX, pointY) : \n",
    "     return np.degrees(np.arccos(pointY @ pointX.T))\n",
    "def check_perpendicular_limb(pointX, pointY, allowed_error = 15) :\n",
    "     limb_xaxis_angle = np.degrees(np.arccos(pointX @ pointY.T))\n",
    "     print(limb_xaxis_angle)\n",
    "     if abs(limb_xaxis_angle - 90) > allowed_error:\n",
    "        return False\n",
    "     else:\n",
    "        return True\n",
    "def calculate_distance(pointX, pointY) :\n",
    "     return np.linalg.norm(pointY - pointX)\n",
    "def analyze_pose(results, visibility_threshold: int) : \n",
    "     landmarks = results.pose_landmarks.landmark\n",
    "     \n",
    "     left_shoulder = point_to_array(landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value])\n",
    "     right_shoulder = point_to_array(landmarks[mp_pose.PoseLandmark.RIGHT_SHOULDER.value])\n",
    "     left_hip = point_to_array(landmarks[mp_pose.PoseLandmark.LEFT_HIP.value])\n",
    "     right_hip = point_to_array( landmarks[mp_pose.PoseLandmark.RIGHT_HIP.value])\n",
    "     left_ankle = point_to_array(landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value])\n",
    "     right_ankle = point_to_array( landmarks[mp_pose.PoseLandmark.RIGHT_ANKLE.value])\n",
    "     left_wrist = point_to_array(landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value])\n",
    "     right_wrist = point_to_array( landmarks[mp_pose.PoseLandmark.RIGHT_WRIST.value])\n",
    "     left_elbow = point_to_array(landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value])\n",
    "     right_elbow = point_to_array( landmarks[mp_pose.PoseLandmark.RIGHT_ELBOW.value])\n",
    "     left_knee = point_to_array(landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value])\n",
    "     right_knee = point_to_array( landmarks[mp_pose.PoseLandmark.RIGHT_KNEE.value])\n",
    "     if (left_shoulder[-1] < visibility_threshold or \n",
    "         right_shoulder[-1] < visibility_threshold or \n",
    "         left_hip[-1] < visibility_threshold or \n",
    "         right_hip[-1] < visibility_threshold or \n",
    "         left_ankle[-1] < visibility_threshold or\n",
    "         right_ankle[-1] < visibility_threshold or\n",
    "         left_wrist[-1] < visibility_threshold or\n",
    "         right_wrist[-1] < visibility_threshold or\n",
    "         left_elbow[-1] < visibility_threshold or\n",
    "         right_elbow[-1] < visibility_threshold or\n",
    "         left_knee[-1] < visibility_threshold or\n",
    "         right_knee[-1] < visibility_threshold) :\n",
    "        return analyzed_results\n",
    "     #CHECK BODY STRAIGHT\n",
    "     torso = np.array([(left_shoulder[:3] - left_hip[:3]) + (right_shoulder[:3] - right_hip[:3])])\n",
    "     # torso = np.array(left_shoulder[:3] - left_hip[:3])\n",
    "     # torso = np.array(right_shoulder[:3] - right_hip[:3])\n",
    "     analyzed_results[\"torso\"] = 0\n",
    "     if not check_perpendicular_limb(pointX = torso, pointY = xaxis, allowed_error=5.):\n",
    "          analyzed_results[\"torso\"] = 1\n",
    "     #CHECK STANCE\n",
    "     hip_length = np.linalg.norm(left_hip[:3] - right_hip[:3])\n",
    "     ankle_length = np.linalg.norm(left_ankle[:3] - right_ankle[:3])\n",
    "     analyzed_results[\"stance\"] = 0\n",
    "     if ankle_length > hip_length*2.35 : \n",
    "          analyzed_results[\"stance\"] = 1\n",
    "     elif ankle_length < hip_length:\n",
    "          analyzed_results[\"stance\"] = 2\n",
    "     #CHECK GRIP\n",
    "     shoulder_width = np.linalg.norm(left_shoulder[:3] - right_shoulder[:3])\n",
    "     grip_width = np.linalg.norm(left_wrist[:3] - right_wrist[:3])\n",
    "     analyzed_results[\"grip\"] = 0\n",
    "     if grip_width > shoulder_width*1.85:\n",
    "          analyzed_results[\"grip\"] = 1\n",
    "     elif grip_width < shoulder_width*1.1:\n",
    "          analyzed_results[\"grip\"] = 2\n",
    "     #CHECK DEPTH\n",
    "     hips = np.array([left_hip, right_hip])\n",
    "     knees = np.array([left_knee, right_knee])\n",
    "     h = ( calculate_distance(left_ankle[:3], left_knee[:3]) +  calculate_distance(right_ankle[:3], right_knee[:3]) ) /2\n",
    "     margin = h * 0.25\n",
    "     analyzed_results[\"depth\"] = 0\n",
    "     if(hips[:, 1] >= knees[:, 1] - margin).any() :\n",
    "          analyzed_results[\"depth\"] = 1\n",
    "     #CHECK HAND STRAIGHT\n",
    "     left_shoulder_to_wrist = left_wrist[:3] - left_shoulder[:3]\n",
    "     right_shoulder_to_wrist = right_wrist[:3] - right_shoulder[:3]\n",
    "     left_shoulder_to_elbow = left_elbow[:3] - left_shoulder[:3]\n",
    "     right_shoulder_to_elbow = right_elbow[:3] - right_shoulder[:3]\n",
    "     analyzed_results[\"left_hand_straight\"] = 0\n",
    "     analyzed_results[\"right_hand_straight\"] = 0\n",
    "     if(abs(calculate_degree(left_shoulder_to_wrist, left_shoulder_to_elbow)) > 15):\n",
    "          analyzed_results[\"left_hand_straight\"] = 1\n",
    "     if(abs(calculate_degree(right_shoulder_to_wrist, right_shoulder_to_elbow)) > 15):\n",
    "          analyzed_results[\"right_hand_straight\"] = 1\n",
    "     \n",
    "     return analyzed_results\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"D:\\\\University\\\\Semester5\\\\PBL4-AIPT\\\\deadlift_model\\\\model\\\\deadlift.pkl\", \"rb\") as f:\n",
    "#     count_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anacoda\\envs\\myenv\\lib\\site-packages\\google\\protobuf\\symbol_database.py:78: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[89.91229351]]\n",
      "[[89.93756864]]\n",
      "[[89.95785773]]\n",
      "[[89.97561281]]\n",
      "[[89.98329336]]\n",
      "[[89.98499066]]\n",
      "[[89.98236104]]\n",
      "[[89.98049298]]\n",
      "[[89.98118966]]\n",
      "[[89.98589907]]\n",
      "[[89.99063581]]\n",
      "[[89.9925107]]\n",
      "[[89.99710058]]\n",
      "[[90.00082987]]\n",
      "[[90.00190221]]\n",
      "[[90.00007172]]\n",
      "[[90.00167681]]\n",
      "[[90.00919002]]\n",
      "[[90.02116334]]\n",
      "[[90.01888889]]\n",
      "[[89.98525021]]\n",
      "[[89.97682517]]\n",
      "[[89.9391874]]\n",
      "[[89.93945378]]\n",
      "[[89.9479198]]\n",
      "[[89.96784347]]\n",
      "[[89.98361096]]\n",
      "[[90.00483919]]\n",
      "[[90.08579745]]\n",
      "[[90.15042826]]\n",
      "[[90.18337382]]\n",
      "[[90.22374391]]\n",
      "[[90.27138834]]\n",
      "[[90.26181231]]\n",
      "[[90.26599584]]\n",
      "[[90.25609197]]\n",
      "[[90.26142981]]\n",
      "[[90.2595993]]\n",
      "[[90.21956721]]\n",
      "[[90.19252973]]\n",
      "[[90.14638136]]\n",
      "[[90.10312908]]\n",
      "[[90.09706045]]\n",
      "[[90.09788007]]\n",
      "[[90.10009989]]\n",
      "[[90.09697849]]\n",
      "[[90.10880498]]\n",
      "[[90.08743329]]\n",
      "[[89.99978485]]\n",
      "[[89.97602945]]\n",
      "[[89.91635406]]\n",
      "[[89.8414472]]\n",
      "[[89.79657946]]\n",
      "[[89.70199067]]\n",
      "[[89.63205518]]\n",
      "[[89.62118812]]\n",
      "[[89.61390014]]\n",
      "[[89.5989246]]\n",
      "[[89.59009978]]\n",
      "[[89.58404466]]\n",
      "[[89.56847481]]\n",
      "[[89.55828046]]\n",
      "[[89.54763187]]\n",
      "[[89.52132453]]\n",
      "[[89.49746239]]\n",
      "[[89.47834393]]\n",
      "[[89.47037276]]\n",
      "[[89.46372328]]\n",
      "[[89.47264048]]\n",
      "[[89.4821041]]\n",
      "[[89.48706985]]\n",
      "[[89.49112031]]\n",
      "[[89.50067953]]\n",
      "[[89.50961034]]\n",
      "[[89.51412525]]\n",
      "[[89.51567918]]\n",
      "[[89.51596264]]\n",
      "[[89.51442238]]\n",
      "[[89.50897511]]\n",
      "[[89.50311459]]\n",
      "[[89.50618829]]\n",
      "[[89.50935419]]\n",
      "[[89.51776246]]\n",
      "[[89.5161095]]\n",
      "[[89.51345246]]\n",
      "[[89.51976719]]\n",
      "[[89.52399523]]\n",
      "[[89.53265278]]\n",
      "[[89.52787491]]\n",
      "[[89.49326849]]\n",
      "[[89.51724335]]\n",
      "[[89.52126989]]\n",
      "[[89.56669208]]\n",
      "[[89.58676997]]\n",
      "[[89.6200577]]\n",
      "[[89.69991427]]\n",
      "[[89.74183847]]\n",
      "[[89.77129051]]\n",
      "[[89.87003846]]\n",
      "[[89.91588278]]\n",
      "[[89.94765001]]\n",
      "[[89.98339922]]\n",
      "[[90.00433376]]\n",
      "[[90.03023042]]\n",
      "[[90.13337322]]\n",
      "[[90.18155698]]\n",
      "[[90.20984779]]\n",
      "[[90.2164697]]\n",
      "[[90.21472799]]\n",
      "[[90.19625562]]\n",
      "[[90.19312055]]\n",
      "[[90.17951133]]\n",
      "[[90.12261906]]\n",
      "[[90.0983377]]\n",
      "[[90.08918182]]\n",
      "[[90.08639851]]\n",
      "[[90.09078691]]\n",
      "[[90.10756188]]\n",
      "[[90.11137655]]\n",
      "[[90.09689652]]\n",
      "[[90.06933668]]\n",
      "[[90.04507242]]\n",
      "[[90.01351694]]\n",
      "[[89.96053516]]\n",
      "[[89.92763413]]\n",
      "[[89.89185072]]\n",
      "[[89.85970436]]\n",
      "[[89.82017448]]\n",
      "[[89.77742407]]\n",
      "[[89.71539509]]\n",
      "[[89.7179701]]\n",
      "[[89.73234099]]\n",
      "[[89.75953907]]\n",
      "[[89.7860609]]\n",
      "[[89.77047088]]\n",
      "[[89.78336296]]\n",
      "[[89.7764371]]\n",
      "[[89.74419149]]\n",
      "[[89.69553947]]\n",
      "[[89.6972163]]\n",
      "[[89.70997868]]\n",
      "[[89.72320892]]\n",
      "[[89.73848481]]\n",
      "[[89.74938931]]\n",
      "[[89.75491157]]\n",
      "[[89.75982252]]\n",
      "[[89.76544382]]\n",
      "[[89.77073726]]\n",
      "[[89.774248]]\n",
      "[[89.78119094]]\n"
     ]
    }
   ],
   "source": [
    "video_path = 'D:\\\\University\\\\Semester5\\\\PBL4-AIPT\\\\Data\\\\Dataset\\\\deadlift\\\\deadlift_1.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Counter vars\n",
    "VISIBILITY_THRESHOLD = 0.6\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, image = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Reduce size of a frame\n",
    "        image = rescale_frame(image, 50)\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        results = pose.process(image)\n",
    "        if not results.pose_landmarks:\n",
    "            continue\n",
    "\n",
    "        # Recolor image from BGR to RGB for mediapipe\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks and connections\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, mp_drawing.DrawingSpec(color=(244, 117, 66), thickness=2, circle_radius=2), mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=1))\n",
    "\n",
    "        # Make detection\n",
    "        try:\n",
    "            # * Model prediction for SQUAT counter\n",
    "            # Extract keypoints from frame for the input\n",
    "\n",
    "            # Evaluate model prediction\n",
    "\n",
    "            # Analyze squat pose\n",
    "            analyzed_results= analyze_pose(results=results, visibility_threshold=VISIBILITY_THRESHOLD)\n",
    "\n",
    "            torso_evaluation = analyzed_results[\"torso\"]\n",
    "            legs_evaluation = analyzed_results[\"stance\"]\n",
    "            grip_evaluation = analyzed_results[\"grip\"]\n",
    "            depth_evaluation = analyzed_results[\"depth\"]\n",
    "            left_hand_straight = analyzed_results[\"left_hand_straight\"]\n",
    "            right_hand_straight = analyzed_results[\"right_hand_straight\"]\n",
    "            state_evaluation = analyzed_results[\"state\"]\n",
    "            # * Evaluate FOOT PLACEMENT error\n",
    "            if torso_evaluation == -1:\n",
    "                torso_placement = \"UNK\"\n",
    "            elif torso_evaluation == 0:\n",
    "                torso_placement = \"Correct\"\n",
    "            elif torso_evaluation == 1:\n",
    "                torso_placement = \"Curved\"\n",
    "            \n",
    "            # * Evaluate KNEE PLACEMENT error\n",
    "            if legs_evaluation == -1:\n",
    "                legs_placement = \"UNK\"\n",
    "            elif legs_evaluation == 0:\n",
    "                legs_placement = \"Correct\"\n",
    "            elif legs_evaluation == 1:\n",
    "                legs_placement = \"Too wide\"\n",
    "            elif legs_evaluation == 2:\n",
    "                legs_placement = \"Too tight\"\n",
    "            \n",
    "            if grip_evaluation == -1:\n",
    "                grip_placement = \"UNK\"\n",
    "            elif grip_evaluation == 0:\n",
    "                grip_placement = \"Correct\"\n",
    "            elif grip_evaluation == 1:\n",
    "                grip_placement = \"Too wide\"\n",
    "            elif grip_evaluation == 2:\n",
    "                grip_placement = \"Too tight\"\n",
    "            \n",
    "            # if left_hand_straight == -1 : \n",
    "            #     left_hand_placement = \"UNK\"\n",
    "            # elif left_hand_straight == 0 : \n",
    "            #     left_hand_placement = \"Correct\"\n",
    "            # elif left_hand_straight == 1 : \n",
    "            #     left_hand_placement = \"Curved\"\n",
    "                \n",
    "            # if right_hand_straight == -1 : \n",
    "            #     right_hand_placement = \"UNK\"\n",
    "            # elif right_hand_straight == 0 : \n",
    "            #     right_hand_placement = \"Correct\"\n",
    "            # elif right_hand_straight == 1 : \n",
    "            #     right_hand_placement = \"Curved\"\n",
    "            # Visualization\n",
    "            # Status box\n",
    "            cv2.rectangle(image, (0, 0), (900, 60), (245, 117, 16), -1)\n",
    "\n",
    "            # Display class\n",
    "            cv2.putText(image, \"TORSO\", (10, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, torso_placement, (5, 40), cv2.FONT_HERSHEY_COMPLEX, .7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Display Foot and Shoulder width ratio\n",
    "            cv2.putText(image, \"LEGS\", (200, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, legs_placement, (195, 40), cv2.FONT_HERSHEY_COMPLEX, .7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "            # Display knee and Shoulder width ratio\n",
    "            cv2.putText(image, \"GRIP\", (330, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, grip_placement, (325, 40), cv2.FONT_HERSHEY_COMPLEX, .7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            cv2.putText(image, \"LEFT_HAND\", (460, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image, str(left_hand_straight), (455, 40), cv2.FONT_HERSHEY_COMPLEX, .7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(image, \"RIGHT_HAND\", (590, 12), cv2.FONT_HERSHEY_COMPLEX, 0.5, (0, 0, 0), 1, cv2.LINE_AA)\n",
    "            cv2.putText(image,str(right_hand_straight), (585, 40), cv2.FONT_HERSHEY_COMPLEX, .7, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        cv2.imshow(\"CV2\", image)\n",
    "        \n",
    "        # Press Q to close cv2 window\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # (Optional)Fix bugs cannot close windows in MacOS (https://stackoverflow.com/questions/6116564/destroywindow-does-not-close-window-on-mac-using-python-and-opencv)\n",
    "    for i in range (1, 5):\n",
    "        cv2.waitKey(1)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  1 222   3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "x = np.array([1, 222, 3, 4])\n",
    "y = np.array([-3, 0, 122])\n",
    "# print(((x*y).sum()))\n",
    "# print(x@y)\n",
    "print(x[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
